# ============================================================
# üì¶ src/pdv_preprocessing/domain/geolocation_service.py
# ============================================================

import os
import time
import requests
import logging
from concurrent.futures import ThreadPoolExecutor, as_completed
from random import uniform
from pdv_preprocessing.infrastructure.database_reader import DatabaseReader
from pdv_preprocessing.infrastructure.database_writer import DatabaseWriter


class GeolocationService:
    """
    Servi√ßo de georreferenciamento unificado:
      - Cache em mem√≥ria e banco
      - Fallback: Cache ‚Üí Nominatim p√∫blico ‚Üí Google
      - Execu√ß√£o paralela com retries e backoff
      - Compat√≠vel com PDV e MKP
    """

    def __init__(self, reader: DatabaseReader, writer: DatabaseWriter, max_workers: int = 20):
        self.reader = reader
        self.writer = writer
        self.GOOGLE_KEY = os.getenv("GMAPS_API_KEY")
        self.NOMINATIM_PUBLIC = "https://nominatim.openstreetmap.org/search"
        self.timeout = 5
        self.max_workers = max_workers

        self.cache_mem = {}
        self.stats = {
            "cache_mem": 0,
            "cache_db": 0,
            "nominatim_public": 0,
            "google": 0,
            "falha": 0,
            "total": 0,
        }

    # ============================================================
    # üß≠ Coordenadas gen√©ricas conhecidas (para descartar)
    # ============================================================
    def _is_generic_location(self, lat: float, lon: float) -> bool:
        if lat is None or lon is None:
            return True
        pontos_genericos = [
            (-23.5506507, -46.6333824),  # S√£o Paulo
            (-22.908333, -43.196388),    # Rio de Janeiro
            (-15.7801, -47.9292),        # Bras√≠lia
            (-19.9167, -43.9345),        # Belo Horizonte
        ]
        for ref_lat, ref_lon in pontos_genericos:
            if abs(lat - ref_lat) < 0.0005 and abs(lon - ref_lon) < 0.0005:
                return True
        return False

    # ============================================================
    # üåç Busca coordenadas com fallback inteligente (auto-switch)
    # ============================================================
    def buscar_coordenadas(self, endereco: str | None, cep: str | None = None) -> tuple[float, float, str]:
        if not endereco and not cep:
            logging.warning("‚ö†Ô∏è Chamada de geocodifica√ß√£o com par√¢metros vazios.")
            return None, None, "parametro_vazio"

        query = (cep or endereco).strip().lower()
        self.stats["total"] += 1

        # 1Ô∏è‚É£ Cache em mem√≥ria
        if query in self.cache_mem:
            self.stats["cache_mem"] += 1
            lat, lon = self.cache_mem[query]
            logging.debug(f"üì¶ [CACHE_MEM] {query} ‚Üí ({lat}, {lon})")
            return lat, lon, "cache_mem"

        # 2Ô∏è‚É£ Cache no banco
        cache_db = self.reader.buscar_localizacao(endereco) if endereco else self.reader.buscar_localizacao_mkp(cep)
        if cache_db:
            lat, lon = cache_db
            self.stats["cache_db"] += 1
            self.cache_mem[query] = (lat, lon)
            logging.debug(f"üóÑÔ∏è [CACHE_DB] {query} ‚Üí ({lat}, {lon})")
            return lat, lon, "cache_db"

        # ============================================================
        # üö¶ Controle adaptativo (modo degradado tempor√°rio)
        # ============================================================
        now = time.time()
        if getattr(self, "_modo_google_ativo_ate", 0) > now:
            modo_google_ativo = True
        else:
            modo_google_ativo = False

        # ============================================================
        # 3Ô∏è‚É£ Nominatim p√∫blico (modo normal)
        # ============================================================
        if not modo_google_ativo:
            headers = {"User-Agent": "SalesRouter-Geocoder/1.0"}
            url_pub = f"{self.NOMINATIM_PUBLIC}?q={query}+Brasil&countrycodes=br&format=json"
            for tent in range(3):
                try:
                    r = requests.get(url_pub, headers=headers, timeout=self.timeout)
                    if r.status_code == 200:
                        dados = r.json()
                        if isinstance(dados, list) and len(dados) > 0:
                            lat, lon = float(dados[0]["lat"]), float(dados[0]["lon"])
                            if not self._is_generic_location(lat, lon):
                                self.stats["nominatim_public"] += 1
                                self.cache_mem[query] = (lat, lon)
                                self.writer.salvar_cache(endereco or cep, lat, lon, tipo="mkp" if cep else "pdv")
                                logging.info(f"üåç [NOMINATIM] {query} ‚Üí ({lat}, {lon})")
                                return lat, lon, "nominatim_public"
                            else:
                                logging.warning(f"‚ö†Ô∏è Coordenada gen√©rica descartada para '{query}' ‚Üí ({lat}, {lon})")
                    elif r.status_code == 429:
                        # Too Many Requests ‚Üí ativa fallback Google tempor√°rio
                        logging.warning("üö¶ Nominatim atingiu limite ‚Üí mudando para modo Google por 2 minutos.")
                        self._modo_google_ativo_ate = now + 120
                        modo_google_ativo = True
                        break
                except Exception as e:
                    logging.warning(f"‚ö†Ô∏è Tentativa {tent+1}/3 falhou no Nominatim ‚Üí {e}")
                    if "Network is unreachable" in str(e) or "Max retries" in str(e):
                        # Ativa modo Google tempor√°rio por 2 minutos
                        self._modo_google_ativo_ate = now + 120
                        modo_google_ativo = True
                        break
                time.sleep(0.8 * (2 ** tent) + uniform(0, 0.3))

        # ============================================================
        # 4Ô∏è‚É£ Google Maps fallback (ou modo degradado ativo)
        # ============================================================
        if modo_google_ativo and self.GOOGLE_KEY:
            from urllib.parse import quote
            url_google = (
                f"https://maps.googleapis.com/maps/api/geocode/json?"
                f"address={quote(query+', Brasil')}&key={self.GOOGLE_KEY}"
            )
            try:
                r = requests.get(url_google, timeout=self.timeout)
                if r.status_code == 200:
                    dados = r.json()
                    if dados.get("status") == "OK" and dados.get("results"):
                        loc = dados["results"][0]["geometry"]["location"]
                        lat, lon = loc["lat"], loc["lng"]
                        if not self._is_generic_location(lat, lon):
                            self.stats["google"] += 1
                            self.cache_mem[query] = (lat, lon)
                            self.writer.salvar_cache(endereco or cep, lat, lon, tipo="mkp" if cep else "pdv")
                            logging.info(f"üó∫Ô∏è [GOOGLE] {query} ‚Üí ({lat}, {lon})")
                            return lat, lon, "google"
            except Exception as e:
                logging.warning(f"‚ö†Ô∏è Falha no Google Maps ‚Üí {e}")

        # ‚ùå Nenhum resultado
        self.stats["falha"] += 1
        logging.warning(f"üíÄ Nenhuma coordenada encontrada para '{query}' ap√≥s 3 tentativas.")
        return None, None, "falha"


    # ============================================================
    # ‚ö° Geocodifica√ß√£o em lote (threads com controle adaptativo)
    # ============================================================
    def geocodificar_em_lote(self, entradas: list[str], tipo: str = "PDV") -> dict[str, tuple[float, float, str]]:
        if not entradas:
            return {}

        total = len(entradas)
        # n√∫mero de threads cresce at√© o limite m√°ximo, com base no volume
        max_workers = min(self.max_workers, 10 if total < 1000 else 25 if total < 3000 else 40)
        inicio_total = time.time()
        resultados = {}

        logging.info(f"üöÄ Geocodifica√ß√£o em lote ({tipo}) iniciada: {total} registros | {max_workers} threads")

        # Pequena espera entre disparos para evitar banimento do Nominatim p√∫blico
        def _worker(e):
            # delay aleat√≥rio de 0.05‚Äì0.2s para distribuir carga entre threads
            time.sleep(uniform(0.05, 0.2))
            return self.buscar_coordenadas(e if tipo == 'PDV' else None, e if tipo == 'MKP' else None)

        with ThreadPoolExecutor(max_workers=max_workers) as executor:
            futuros = {executor.submit(_worker, e): e for e in entradas}

            for i, futuro in enumerate(as_completed(futuros), 1):
                chave = futuros[futuro]
                try:
                    coords = futuro.result()
                    if coords:
                        resultados[chave] = coords
                except Exception as e:
                    logging.warning(f"‚ö†Ô∏è Erro geocodificando {chave}: {e}")

                # logs intermedi√°rios
                if i % 200 == 0 or i == total:
                    resolvidos = len(resultados)
                    falhas = self.stats["falha"]
                    logging.info(
                        f"üß© Progresso: {i}/{total} ({100 * i / total:.1f}%) "
                        f"‚Üí {resolvidos} resolvidos | {falhas} falhas"
                    )

                    # throttling adaptativo ‚Äî se falhas >=10%, reduz velocidade
                    if falhas / max(1, i) > 0.1:
                        logging.warning("‚ö†Ô∏è Muitas falhas recentes ‚Äî aplicando pausa preventiva (3s)...")
                        time.sleep(3)

        dur = time.time() - inicio_total
        taxa_ok = (len(resultados) / total * 100) if total else 0
        logging.info(
            f"‚úÖ Conclu√≠do: {len(resultados)}/{total} resolvidos ({taxa_ok:.1f}%) em {dur:.1f}s "
            f"‚Üí m√©dia {dur/total:.2f}s/reg"
        )
        return resultados


    # ============================================================
    # üìä Resumo de logs
    # ============================================================
    def exibir_resumo_logs(self):
        total = self.stats["total"]
        logging.info("üìä Resumo de Geolocaliza√ß√£o:")
        for origem, count in self.stats.items():
            if origem != "total":
                pct = (count / total * 100) if total else 0
                logging.info(f"   {origem:<18}: {count:>6} ({pct:5.1f}%)")
        logging.info(f"   total               : {total:>6}")

        sucesso = total - self.stats["falha"]
        taxa = (sucesso / total * 100) if total else 0
        logging.info(f"‚úÖ Taxa de sucesso: {sucesso}/{total} ({taxa:.1f}%)")

