import pandas as pd
import numpy as np
import re
from loguru import logger


class PDVValidationService:
    """
    Servi√ßo de valida√ß√£o de PDVs.
    - Limpa e valida CNPJ/CEP.
    - Detecta campos obrigat√≥rios ausentes (exceto 'bairro', que √© opcional).
    - Evita duplicados no CSV e no banco para o mesmo tenant.
    """

    def __init__(self, db_reader=None):
        """
        Pode receber o DatabaseReader opcionalmente
        para verificar duplicidades no banco.
        """
        self.db_reader = db_reader

    # ============================================================
    # üîπ Limpeza de CNPJ e CEP
    # ============================================================
    @staticmethod
    def limpar_cnpj(cnpj: str) -> str | None:
        """Remove caracteres n√£o num√©ricos e valida tamanho."""
        if not cnpj or pd.isna(cnpj):
            return None
        cnpj = re.sub(r"[^0-9]", "", str(cnpj))
        return cnpj if len(cnpj) == 14 else None

    @staticmethod
    def limpar_cep(cep: str) -> str | None:
        """Remove caracteres n√£o num√©ricos e normaliza para 8 d√≠gitos."""
        if not cep or pd.isna(cep):
            return None
        cep = re.sub(r"[^0-9]", "", str(cep))
        return cep.zfill(8) if len(cep) in (5, 8) else None

    # ============================================================
    # üîç Valida√ß√£o principal
    # ============================================================
    def validar_dados(
        self,
        df: pd.DataFrame,
        tenant_id: int | None = None,
        input_id: str | None = None,
    ) -> tuple[pd.DataFrame, pd.DataFrame]:
        """
        Valida campos obrigat√≥rios e duplicidades (CSV + banco, somente dentro do mesmo input_id).
        Retorna dois DataFrames: v√°lidos e inv√°lidos (com motivo).
        """

        campos_obrigatorios = ["cnpj", "logradouro", "numero", "cidade", "uf", "cep"]

        # ============================================================
        # üßπ Normaliza strings vazias
        # ============================================================
        df[campos_obrigatorios] = df[campos_obrigatorios].replace("", np.nan)

        # ‚ÑπÔ∏è Log de auditoria: aus√™ncia de bairro
        if "bairro" in df.columns:
            total_sem_bairro = df["bairro"].eq("").sum()
            logger.info(f"‚ÑπÔ∏è [{tenant_id}] {total_sem_bairro} PDV(s) sem bairro informado.")
        else:
            logger.info(f"‚ÑπÔ∏è [{tenant_id}] Coluna 'bairro' ausente (opcional).")

        # ============================================================
        # üö´ Campos obrigat√≥rios ausentes
        # ============================================================
        registros_invalidos = df[df[campos_obrigatorios].isna().any(axis=1)].copy()
        if not registros_invalidos.empty:
            registros_invalidos["motivo_invalidade"] = registros_invalidos.apply(
                lambda row: ", ".join([c for c in campos_obrigatorios if pd.isna(row[c])]),
                axis=1,
            )
            logger.warning(f"‚ö†Ô∏è [{tenant_id}] {len(registros_invalidos)} registro(s) com campos obrigat√≥rios faltando.")

        # Mant√©m v√°lidos
        df_validos = df.dropna(subset=campos_obrigatorios).copy()

        # ============================================================
        # 1Ô∏è‚É£ Duplicados no pr√≥prio arquivo
        # ============================================================
        duplicados_csv = df_validos[df_validos.duplicated(subset=["cnpj"], keep=False)].copy()
        if not duplicados_csv.empty:
            duplicados_csv["motivo_invalidade"] = "CNPJ duplicado no arquivo"
            registros_invalidos = pd.concat([registros_invalidos, duplicados_csv], ignore_index=True)
            df_validos = df_validos[~df_validos["cnpj"].isin(duplicados_csv["cnpj"])]
            logger.warning(f"‚ö†Ô∏è [{tenant_id}] {len(duplicados_csv)} CNPJs duplicados no arquivo CSV.")

        # ============================================================
        # 2Ô∏è‚É£ Duplicados no banco ‚Äî somente dentro do mesmo input_id
        # ============================================================
        if self.db_reader and tenant_id and input_id:
            try:
                cnpjs_existentes = self.db_reader.buscar_cnpjs_existentes(tenant_id, input_id)
                if cnpjs_existentes:
                    duplicados_banco = df_validos[df_validos["cnpj"].isin(cnpjs_existentes)].copy()
                    if not duplicados_banco.empty:
                        duplicados_banco["motivo_invalidade"] = "CNPJ duplicado neste input_id"
                        registros_invalidos = pd.concat(
                            [registros_invalidos, duplicados_banco], ignore_index=True
                        )
                        df_validos = df_validos[~df_validos["cnpj"].isin(duplicados_banco["cnpj"])]
                        logger.warning(
                            f"‚ö†Ô∏è [{tenant_id}] {len(duplicados_banco)} CNPJs j√° existentes neste input_id foram ignorados."
                        )
            except Exception as e:
                logger.error(f"‚ùå [{tenant_id}] Erro ao verificar duplicados no banco: {e}", exc_info=True)

        # ============================================================
        # ‚úÖ Resultado final
        # ============================================================
        registros_invalidos = registros_invalidos.drop_duplicates(subset=["cnpj"]).reset_index(drop=True)
        df_validos = df_validos.reset_index(drop=True)

        logger.info(f"‚úÖ [{tenant_id}] {len(df_validos)} v√°lidos / {len(registros_invalidos)} inv√°lidos ap√≥s valida√ß√£o.")
        return df_validos, registros_invalidos
