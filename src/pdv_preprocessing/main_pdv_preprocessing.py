import os
import argparse
import logging
import uuid
import time
import json
from dotenv import load_dotenv

from pdv_preprocessing.application.pdv_preprocessing_use_case import PDVPreprocessingUseCase
from pdv_preprocessing.infrastructure.database_reader import DatabaseReader
from pdv_preprocessing.infrastructure.database_writer import DatabaseWriter
from database.db_connection import get_connection


logging.basicConfig(level=logging.INFO, format="%(asctime)s - %(levelname)s - %(message)s")
load_dotenv()


def detectar_separador(path: str) -> str:
    with open(path, "r", encoding="utf-8-sig") as f:
        linha = f.readline()
        return ";" if ";" in linha else ","


def salvar_invalidos(df_invalidos, pasta_base: str, job_id: str):
    try:
        if df_invalidos is None or df_invalidos.empty:
            return None
        pasta_invalidos = os.path.join(pasta_base, "invalidos")
        os.makedirs(pasta_invalidos, exist_ok=True)
        nome_arquivo = f"pdvs_invalidos_{job_id}.csv"
        caminho_saida = os.path.join(pasta_invalidos, nome_arquivo)
        df_invalidos.to_csv(caminho_saida, index=False, sep=";", encoding="utf-8-sig")
        logging.warning(f"‚ö†Ô∏è {len(df_invalidos)} registro(s) inv√°lido(s) salvo(s) em: {caminho_saida}")
        return caminho_saida
    except Exception as e:
        logging.error(f"‚ùå Erro ao salvar registros inv√°lidos: {e}")
        return None


def main():
    parser = argparse.ArgumentParser(description="Pr√©-processamento de PDVs (SalesRouter multi-tenant)")
    parser.add_argument("--tenant", required=True, help="Tenant ID (inteiro ou vari√°vel TENANT_ID do .env)")
    parser.add_argument("--arquivo", required=True, help="Caminho do CSV de entrada (ex: /app/data/pdvs_enderecos.csv)")
    parser.add_argument("--modo_forcar", action="store_true", help="For√ßa reprocessamento e limpa PDVs anteriores")
    args = parser.parse_args()

    try:
        tenant_id = int(args.tenant or os.getenv("TENANT_ID"))
    except (TypeError, ValueError):
        logging.error("‚ùå Tenant ID inv√°lido ou ausente. Informe um n√∫mero inteiro.")
        return

    input_path = args.arquivo
    if not os.path.exists(input_path):
        logging.error(f"‚ùå Arquivo n√£o encontrado: {input_path}")
        return

    sep = detectar_separador(input_path)
    job_id = str(uuid.uuid4())
    inicio_execucao = time.time()

    logging.info(f"üöÄ Iniciando pr√©-processamento de PDVs (tenant_id={tenant_id}) - Job {job_id}")
    logging.info(f"üìÇ Lendo arquivo de entrada: {input_path} | Separador detectado: '{sep}'")

    try:
        conn = get_connection()
        db_reader = DatabaseReader(conn)
        db_writer = DatabaseWriter(conn)
    except Exception as e:
        logging.error(f"‚ùå Falha ao conectar ao banco de dados: {e}")
        return

    # ============================================================
    # üßπ LIMPEZA AUTOM√ÅTICA SE modo_forcar = True
    # ============================================================
    if args.modo_forcar:
        logging.warning(f"üßπ Modo for√ßar ativado ‚Äî limpando PDVs existentes do tenant_id={tenant_id} ...")
        try:
            with conn.cursor() as cur:
                cur.execute("DELETE FROM pdvs WHERE tenant_id = %s;", (tenant_id,))
                conn.commit()
            logging.info(f"‚úÖ Todos os PDVs anteriores do tenant_id={tenant_id} foram removidos.")
        except Exception as e:
            logging.error(f"‚ùå Erro ao limpar PDVs do tenant_id={tenant_id}: {e}")
            return

    try:
        use_case = PDVPreprocessingUseCase(db_reader, db_writer, tenant_id)
        df_validos, df_invalidos = use_case.execute(input_path, sep)

        total_validos = len(df_validos) if df_validos is not None else 0
        total_invalidos = len(df_invalidos) if df_invalidos is not None else 0
        total = total_validos + total_invalidos
        arquivo_invalidos = salvar_invalidos(df_invalidos, os.path.dirname(input_path), job_id)

        duracao = time.time() - inicio_execucao
        logging.info(f"‚úÖ Processamento conclu√≠do com {total_validos} PDVs v√°lidos.")
        logging.info(f"üíæ Dados gravados no banco para tenant_id={tenant_id}.")
        logging.info(f"‚è±Ô∏è Dura√ß√£o total: {duracao:.2f}s")

        # ============================================================
        # üìä CONTAGEM FINAL DE PDVS NO BANCO
        # ============================================================
        try:
            with get_connection() as conn_final:
                with conn_final.cursor() as cur:
                    cur.execute("SELECT COUNT(*) FROM pdvs WHERE tenant_id = %s;", (tenant_id,))
                    total_final = cur.fetchone()[0]
            logging.info(f"üíæ Total final no banco para tenant_id={tenant_id}: {total_final} PDVs.")
        except Exception as e:
            logging.error(f"‚ùå Erro ao consultar total final de PDVs: {e}")
            total_final = None

        print(json.dumps({
            "status": "done",
            "job_id": job_id,
            "tenant_id": tenant_id,
            "arquivo": os.path.basename(input_path),
            "total_processados": total,
            "validos": total_validos,
            "invalidos": total_invalidos,
            "arquivo_invalidos": arquivo_invalidos,
            "duracao_segundos": round(duracao, 2),
            "total_final_banco": total_final
        }))

    except Exception as e:
        logging.error(f"‚ùå Erro inesperado: {e}", exc_info=True)
        print(json.dumps({
            "status": "error",
            "erro": str(e),
            "job_id": job_id,
            "tenant_id": tenant_id
        }))


if __name__ == "__main__":
    main()
