#sales_router/src/sales_clusterization/jobs.py

import os
import re
import json
import subprocess
from datetime import datetime
from rq import get_current_job
from loguru import logger
from src.database.pipeline_history_service import registrar_historico_pipeline


# ============================================================
# üöÄ Fun√ß√£o: processar clusteriza√ß√£o (pipeline ass√≠ncrono)
# ============================================================
def processar_clusterizacao(job_id, tenant_id, uf, cidade, algo, k_forcado=None, modo_forcar=False):
    """
    Executa o processo de clusteriza√ß√£o de PDVs de forma ass√≠ncrona (via RQ).
    - Cria um subprocesso para rodar o m√≥dulo principal da clusteriza√ß√£o.
    - Registra o progresso no hist√≥rico do pipeline.
    """
    job = get_current_job()
    etapa = "clusterization"

    logger.info(f"üöÄ Iniciando job de clusteriza√ß√£o ({job_id}) | tenant={tenant_id} | {uf}-{cidade} | algo={algo}")

    # 1Ô∏è‚É£ Atualiza hist√≥rico inicial
    registrar_historico_pipeline(
        tenant_id=tenant_id,
        job_id=job_id,                     # ‚úÖ Adicionado
        etapa=etapa,
        status="running",
        mensagem=f"Iniciando clusteriza√ß√£o ({uf}-{cidade})",
    )

    try:
        # ============================================================
        # üîß Monta comando CLI
        # ============================================================
        comando = [
            "python3",
            "-m",
            "src.sales_clusterization.cli.run_cluster",
            "--tenant_id", str(tenant_id),
            "--uf", uf,
            "--cidade", cidade,
            "--algo", algo,
        ]

        if k_forcado:
            comando += ["--k", str(k_forcado)]
        if modo_forcar:
            comando.append("--modo_forcar")

        logger.info(f"‚ñ∂Ô∏è Executando comando: {' '.join(comando)}")

        # ============================================================
        # üîÑ Executa subprocesso com PYTHONPATH corrigido
        # ============================================================
        process = subprocess.Popen(
            comando,
            stdout=subprocess.PIPE,
            stderr=subprocess.STDOUT,
            text=True,
            encoding="utf-8",
            errors="ignore",
            env={**os.environ, "PYTHONPATH": "/app/src"},  # ‚úÖ Corrige path
        )

        linhas = []
        for line in iter(process.stdout.readline, ""):
            line = line.strip()
            if line:
                logger.info(f"[{job_id}] {line}")
                linhas.append(line)

        process.wait()

        if process.returncode != 0:
            logger.error(f"‚ùå Clusteriza√ß√£o falhou com c√≥digo {process.returncode}")
            raise Exception("\n".join(linhas))

        # ============================================================
        # üß† Interpreta resultado
        # ============================================================
        resumo = None
        for line in linhas:
            if line.startswith("{") and line.endswith("}"):
                try:
                    resumo = json.loads(line)
                    break
                except Exception:
                    pass

        if resumo:
            msg = f"‚úÖ Clusteriza√ß√£o conclu√≠da com sucesso | run_id={resumo.get('run_id')} | K={resumo.get('k_final')}"
            logger.success(msg)
        else:
            msg = "‚úÖ Clusteriza√ß√£o conclu√≠da (sem resumo JSON detectado)."
            logger.success(msg)

        # ============================================================
        # üíæ Atualiza hist√≥rico final
        # ============================================================
        registrar_historico_pipeline(
            tenant_id=tenant_id,
            job_id=job_id,                # ‚úÖ Adicionado
            etapa=etapa,
            status="done",
            mensagem=msg,
            metadata={"resultado": resumo or {}},
        )

        return {
            "status": "done",
            "job_id": job_id,
            "tenant_id": tenant_id,
            "uf": uf,
            "cidade": cidade,
            "algo": algo,
            "resultado": resumo or {},
        }

    except Exception as e:
        logger.error(f"‚ùå Erro no job {job_id}: {e}", exc_info=True)
        registrar_historico_pipeline(
            tenant_id=tenant_id,
            job_id=job_id,               # ‚úÖ Adicionado
            etapa=etapa,
            status="error",
            mensagem=str(e),
        )
        return {
            "status": "error",
            "job_id": job_id,
            "tenant_id": tenant_id,
            "erro": str(e),
        }
