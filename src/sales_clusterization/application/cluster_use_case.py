#sales_router/src/sales_clusterization/application/cluster_use_case.py

# ============================================================
# üì¶ src/sales_clusterization/application/cluster_use_case.py
# ============================================================

from typing import Optional, Dict, Any, List
from loguru import logger
import numpy as np
from sklearn.neighbors import NearestNeighbors
import math


from src.sales_clusterization.domain.sector_generator import kmeans_balanceado
from src.sales_clusterization.infrastructure.persistence.database_reader import carregar_pdvs
from src.sales_clusterization.infrastructure.persistence.database_writer import (
    criar_run,
    finalizar_run,
    salvar_setores,
    salvar_mapeamento_pdvs,
    salvar_outliers,
)
from src.sales_clusterization.infrastructure.logging.run_logger import snapshot_params
from src.sales_clusterization.domain.k_estimator import estimar_k_inicial
from src.sales_clusterization.domain.sector_generator import kmeans_setores
from src.sales_clusterization.domain.sector_generator_hybrid import dbscan_kmeans_balanceado
from src.sales_clusterization.domain.validators import checar_raio
from src.sales_clusterization.domain.entities import PDV
from src.sales_clusterization.domain.operational_cluster_refiner import OperationalClusterRefiner


# ============================================================
# üß† Detec√ß√£o de Outliers Geogr√°ficos (vers√£o mais sens√≠vel)
# ============================================================
def detectar_outliers_geograficos(
    pdvs: List[PDV],
    z_thresh: float = 1.8,  # üîπ antes 2.0 ‚Üí mais sens√≠vel
    metodo: Optional[str] = None,
    limite_urbano_km: Optional[float] = None,
):
    if len(pdvs) < 5:
        logger.warning("‚ö†Ô∏è Poucos PDVs para detec√ß√£o de outliers ‚Äî nenhum removido.")
        return [(p, False) for p in pdvs]

    coords = np.array([[p.lat, p.lon] for p in pdvs])
    coords_rad = np.radians(coords)
    k = min(5, len(coords) - 1)
    nn = NearestNeighbors(n_neighbors=k + 1, metric="haversine")
    nn.fit(coords_rad)
    dist, _ = nn.kneighbors(coords_rad)

    dist_min = dist[:, 1] * 6371.0
    media_k5 = np.mean(dist[:, -1]) * 6371.0
    limite_dinamico = np.clip(media_k5 * 6, 3, 10)  # üîπ antes 7√ó ‚Äî menor = mais sens√≠vel

    if limite_urbano_km is None:
        limite_urbano_km = limite_dinamico

    dist_mean = np.mean(dist_min)
    dist_std = np.std(dist_min)
    q1, q3 = np.percentile(dist_min, [25, 75])
    iqr = q3 - q1

    # üîπ Sele√ß√£o adaptativa do m√©todo
    if metodo is None:
        if dist_std < 2:
            metodo = "iqr"
        elif dist_std > 5:
            metodo = "zscore"
        else:
            metodo = "hibrido"

    # üîπ Ajuste dos limiares para mais sensibilidade
    if metodo == "iqr":
        limiar = q3 + 1.8 * iqr            # antes 2.5
    elif metodo == "zscore":
        limiar = dist_mean + z_thresh * 1.5 * dist_std  # antes z_thresh * std
    else:
        limiar_z = dist_mean + z_thresh * 1.5 * dist_std
        limiar_iqr = q3 + 1.8 * iqr
        limiar = (min(limiar_z, limiar_iqr) * 0.6) + (limite_urbano_km * 0.4)

    flags = dist_min > limiar
    removidos = np.sum(flags)
    logger.info(
        f"üßπ Outliers detectados={removidos}/{len(pdvs)} "
        f"| m√©todo={metodo} | limiar={limiar:.2f} km"
    )

    # üö® Alerta se dispers√£o acima do esperado
    if removidos / len(pdvs) > 0.05:
        logger.warning(
            f"üö® {removidos} outliers ({removidos/len(pdvs):.1%}) ‚Äî alta dispers√£o detectada."
        )

    return [(pdvs[i], bool(flags[i])) for i in range(len(pdvs))]



# ============================================================
# üöÄ Execu√ß√£o principal da clusteriza√ß√£o
# ============================================================
def executar_clusterizacao(
    tenant_id: int,
    uf: Optional[str],
    cidade: Optional[str],
    algo: str,
    k_forcado: Optional[int],
    dias_uteis: int,
    freq: int,
    workday_min: int,
    route_km_max: float,
    service_min: int,
    v_kmh: float,
    alpha_path: float,
    max_pdv_cluster: int,
    descricao: str,
    input_id: str,
    clusterization_id: str,
    excluir_outliers: bool = False,
    z_thresh: float = 1.5,
    max_iter: int = 10,  # üÜï N√∫mero m√°ximo de itera√ß√µes (parametriz√°vel)
) -> Dict[str, Any]:
    """
    Executa o fluxo completo de clusteriza√ß√£o com detec√ß√£o robusta de outliers
    e refinamento operacional iterativo. 
    Agora com limite de itera√ß√µes configur√°vel (max_iter).
    """

    logger.info(
        f"üèÅ Iniciando clusteriza√ß√£o | tenant_id={tenant_id} | {uf}-{cidade} "
        f"| algo={algo} | input_id={input_id} | max_iter={max_iter}"
    )


    # ============================================================
    # 1Ô∏è‚É£ Carrega PDVs
    # ============================================================
    pdvs = carregar_pdvs(tenant_id=tenant_id, input_id=input_id, uf=uf, cidade=cidade)
    if not pdvs:
        raise ValueError(f"Nenhum PDV encontrado para tenant_id={tenant_id}, input_id={input_id}.")

    logger.info(f"‚úÖ {len(pdvs)} PDVs carregados (input_id={input_id}).")

    # ============================================================
    # 2Ô∏è‚É£ Detecta e salva outliers
    # ============================================================
    pdv_flags = detectar_outliers_geograficos(pdvs, z_thresh=z_thresh, metodo="hibrido")
    total_outliers = sum(1 for _, flag in pdv_flags if flag)

    outliers_data = [
        {"pdv_id": getattr(p, "id", None), "lat": p.lat, "lon": p.lon, "is_outlier": bool(flag)}
        for p, flag in pdv_flags
    ]
    try:
        salvar_outliers(tenant_id, clusterization_id, outliers_data)
    except Exception as e:
        logger.warning(f"‚ö†Ô∏è Falha ao salvar outliers: {e}")

    if excluir_outliers:
        pdvs = [p for p, flag in pdv_flags if not flag]
        logger.info(f"üìâ {total_outliers} outliers removidos | {len(pdvs)} PDVs restantes.")
    else:
        logger.info("‚úÖ Outliers inclu√≠dos (nenhum removido).")

    # ============================================================
    # 3Ô∏è‚É£ Snapshot de par√¢metros e cria√ß√£o de run
    # ============================================================
    params = snapshot_params(
        uf=uf,
        cidade=cidade,
        algo=algo,
        k_forcado=k_forcado,
        dias_uteis=dias_uteis,
        freq=freq,
        workday_min=workday_min,
        route_km_max=route_km_max,
        service_min=service_min,
        v_kmh=v_kmh,
        alpha_path=alpha_path,
        n_pdvs=len(pdvs),
        max_pdv_cluster=max_pdv_cluster,
        descricao=descricao,
        input_id=input_id,
        clusterization_id=clusterization_id,
    )

    run_id = criar_run(
        tenant_id=tenant_id,
        uf=uf,
        cidade=cidade,
        algo=algo,
        params=params,
        descricao=descricao,
        input_id=input_id,
        clusterization_id=clusterization_id,
    )
    logger.info(f"üÜï Execu√ß√£o registrada | run_id={run_id}")

    try:
        # ============================================================
        # 4Ô∏è‚É£ Instancia refinador operacional
        # ============================================================
        refiner = OperationalClusterRefiner(
            v_kmh=v_kmh,
            max_time_min=workday_min,
            max_dist_km=route_km_max,
            tempo_servico_min=service_min,
            max_iter=max_iter,
            tenant_id=tenant_id,  # üëà adicionado
        )

         # ============================================================
        # 4Ô∏è‚É£-B NOVO MODO: KMEANS_SIMPLES (DEFAULT)
        # ============================================================
        if algo in ("kmeans_simples", "simples", None):
            logger.info("üß† Modo simples: clusteriza√ß√£o apenas por n√∫mero m√°ximo de PDVs (sem refino operacional).")

            total_pdvs = len(pdvs)
            k_inicial = max(1, math.ceil(total_pdvs / max_pdv_cluster))
            logger.info(f"üìä Total {total_pdvs} PDVs | M√°x {max_pdv_cluster}/cluster ‚Üí K inicial = {k_inicial}")

            # üßÆ Executa KMeans padr√£o (centros seguem densidade natural)
            setores_finais, labels = kmeans_setores(pdvs, k_inicial)

            # üß© Atualiza labels de cada PDV
            for i, p in enumerate(pdvs):
                p.cluster_label = int(labels[i]) if i < len(labels) else -1

            # üó∫Ô∏è Loga resumo por cluster
            for s in setores_finais:
                logger.debug(
                    f"üìç Cluster {s.cluster_label}: {s.n_pdvs} PDVs | "
                    f"Centro=({s.centro_lat:.5f}, {s.centro_lon:.5f}) | "
                    f"Raio med={s.raio_med_km:.2f} km | P95={s.raio_p95_km:.2f} km"
                )

            # üíæ Salva setores e mapeamento PDVs
            mapping_cluster_id = salvar_setores(tenant_id, run_id, setores_finais)
            label_to_id = {s.cluster_label: mapping_cluster_id.get(s.cluster_label) for s in setores_finais}
            for p in pdvs:
                if p.cluster_label in label_to_id:
                    p.cluster_id = label_to_id[p.cluster_label]

            salvar_mapeamento_pdvs(tenant_id, run_id, pdvs)

            # ‚úÖ Finaliza execu√ß√£o
            finalizar_run(run_id, status="done", k_final=k_inicial)
            logger.success(f"‚úÖ Clusteriza√ß√£o simples conclu√≠da | K={k_inicial} | run_id={run_id}")

            return {
                "tenant_id": tenant_id,
                "clusterization_id": clusterization_id,  # ‚úÖ adicionada
                "run_id": run_id,
                "algo": algo,
                "k_final": k_inicial,
                "n_pdvs": len(pdvs),
                "outliers": total_outliers,
                "diagnostico": f"Clusteriza√ß√£o simples conclu√≠da com K={k_inicial} e {len(pdvs)} PDVs."
            }




        # ============================================================
        # 5Ô∏è‚É£ KMEANS ‚Üí clusteriza√ß√£o operacional iterativa completa
        # ============================================================
        if algo == "kmeans":
            if k_forcado:
                k0 = k_forcado
                diag = {"modo": "for√ßado"}
                logger.info(f"üìé K for√ßado recebido: {k0}")
            else:
                k0, diag = estimar_k_inicial(
                    pdvs=pdvs,
                    workday_min=workday_min,
                    route_km_max=route_km_max,
                    service_min=service_min,
                    v_kmh=v_kmh,
                    dias_uteis=dias_uteis,
                    freq=freq,
                    max_pdv_cluster=max_pdv_cluster,
                    alpha_path=alpha_path,
                )

            
            logger.info("üß≠ Executando KMeans balanceado com refinamento autom√°tico...")
            setores_finais = kmeans_balanceado(
                pdvs=pdvs,
                max_pdv_cluster=max_pdv_cluster,
                v_kmh=v_kmh,
                max_dist_km=route_km_max,
                max_time_min=workday_min,
                tempo_servico_min=service_min,
            )

            # ============================================================
            # üöö Gera√ß√£o de subrotas te√≥ricas + reclusteriza√ß√£o hier√°rquica
            # ============================================================
            logger.info("üöö Gerando subrotas te√≥ricas e avaliando limites operacionais...")
            setores_finais = refiner.gerar_subrotas_teoricas(
                pdvs=pdvs,
                setores_macro=setores_finais,
                dias_uteis=dias_uteis,
                freq=freq,
                max_pdv_cluster=max_pdv_cluster,
            )


          
            # üìä Diagn√≥stico p√≥s-refinamento ‚Äî consolida tempos e dist√¢ncias das rotas te√≥ricas
            tempos = [
                sc.get("tempo_min", 0)
                for s in setores_finais
                if getattr(s, "subclusters", None)
                for sc in (s.subclusters or [])
            ]

            distancias = [sc.get("dist_km", 0) for s in setores_finais for sc in getattr(s, "subclusters", [])]
            excedidos = [
                sc for s in setores_finais for sc in getattr(s, "subclusters", [])
                if sc.get("status") == "EXCEDIDO"
            ]

            tempo_medio_min = np.mean(tempos) if tempos else 0
            tempo_max_min = np.max(tempos) if tempos else 0
            distancia_media_km = np.mean(distancias) if distancias else 0
            dist_max_km = np.max(distancias) if distancias else 0

            diag["refinamento_operacional"] = {
                "clusters_excedidos": len(excedidos),
                "tempo_medio_min": round(float(tempo_medio_min), 2),
                "tempo_max_min": round(float(tempo_max_min), 2),
                "distancia_media_km": round(float(distancia_media_km), 2),
                "dist_max_km": round(float(dist_max_km), 2),
                "k_final": len(setores_finais),
                "dias_uteis": dias_uteis,
                "freq": freq,
                "subrotas_planejadas": max(1, int(dias_uteis / max(freq, 1))),
            }

            logger.info("üìä Diagn√≥stico consolidado (rotas te√≥ricas):")
            logger.info(f"   - Clusters finais: {len(setores_finais)} | excedidos: {len(excedidos)}")
            logger.info(
                f"   - Tempo m√©dio: {tempo_medio_min:.1f} min (m√°x {tempo_max_min:.1f}) | "
                f"Dist√¢ncia m√©dia: {distancia_media_km:.1f} km (m√°x {dist_max_km:.1f})"
            )


        # ============================================================
        # 6Ô∏è‚É£ DBSCAN h√≠brido balanceado (mantido)
        # ============================================================
        elif algo == "dbscan":
            logger.info("üîπ Executando DBSCAN balanceado...")
            setores, labels = dbscan_kmeans_balanceado(pdvs, max_pdv_cluster=max_pdv_cluster)
            for i, p in enumerate(pdvs):
                p.cluster_label = int(labels[i])
            setores_finais = refiner.subdividir_excedidos(setores, pdvs)
            avaliacoes = refiner.avaliar_clusters(setores_finais)
            diag = {"refinamento_operacional": {"clusters_excedidos": sum(r["status"] == "EXCEDIDO" for r in avaliacoes)}}

        # ============================================================
        # 7Ô∏è‚É£ Pipeline h√≠brido DBSCAN ‚Üí KMeans ‚Üí Subclusteriza√ß√£o di√°ria
        # ============================================================
        elif algo == "hibrido":
            logger.info("üß© Executando pipeline h√≠brido DBSCAN ‚Üí KMeans balanceado...")

            setores, labels = dbscan_kmeans_balanceado(
                pdvs=pdvs,
                max_pdv_cluster=max_pdv_cluster,
                frequencia_visita=freq,
                dias_uteis=dias_uteis,
                workday_min=workday_min,
                tempo_servico_min=service_min,
                v_kmh=v_kmh,
            )

            for i, p in enumerate(pdvs):
                p.cluster_label = int(labels[i])

            # ========================================================
            # üöö Subclusteriza√ß√£o di√°ria iterativa (rotas ‚â§ 600 min)
            # ========================================================
            logger.info("üöö Iniciando subclusteriza√ß√£o di√°ria iterativa (rotas ‚â§ tempo m√°ximo)...")

            setores_finais = refiner.refinar_com_subclusters_iterativo(
                pdvs=pdvs,
                dias_uteis=dias_uteis,
                freq=freq,
                max_pdv_cluster=max_pdv_cluster,
            )

            # ========================================================
            # üìä Diagn√≥stico p√≥s-refinamento (similar ao modo KMeans)
            # ========================================================
            tempos = [sc["tempo_min"] for s in setores_finais for sc in getattr(s, "subclusters", [])]
            distancias = [sc["dist_km"] for s in setores_finais for sc in getattr(s, "subclusters", [])]
            excedidos = [sc for s in setores_finais for sc in getattr(s, "subclusters", []) if sc["status"] == "EXCEDIDO"]

            tempo_medio_min = np.mean(tempos) if tempos else 0
            tempo_max_min = np.max(tempos) if tempos else 0
            distancia_media_km = np.mean(distancias) if distancias else 0
            dist_max_km = np.max(distancias) if distancias else 0

            diag = {
                "refinamento_operacional": {
                    "clusters_excedidos": len(excedidos),
                    "tempo_medio_min": round(float(tempo_medio_min), 2),
                    "tempo_max_min": round(float(tempo_max_min), 2),
                    "distancia_media_km": round(float(distancia_media_km), 2),
                    "dist_max_km": round(float(dist_max_km), 2),
                    "k_final": len(setores_finais),
                    "dias_uteis": dias_uteis,
                    "freq": freq,
                    "subrotas_planejadas": max(1, int(dias_uteis / max(freq, 1))),
                }
            }

            logger.info("üìä Diagn√≥stico h√≠brido p√≥s-subclusteriza√ß√£o:")
            logger.info(f"   - Clusters finais: {len(setores_finais)} | excedidos: {len(excedidos)}")
            logger.info(
                f"   - Tempo m√©dio: {tempo_medio_min:.1f} min (m√°x {tempo_max_min:.1f}) | "
                f"Dist√¢ncia m√©dia: {distancia_media_km:.1f} km (m√°x {dist_max_km:.1f})"
            )



        # ============================================================
        # 7Ô∏è‚É£ Persist√™ncia final
        # ============================================================
        mapping_cluster_id = salvar_setores(tenant_id, run_id, setores_finais)
        label_to_id = {s.cluster_label: mapping_cluster_id.get(s.cluster_label) for s in setores_finais}
        for p in pdvs:
            if p.cluster_label in label_to_id:
                p.cluster_id = label_to_id[p.cluster_label]
        salvar_mapeamento_pdvs(tenant_id, run_id, pdvs)

        k_final_exec = diag.get("refinamento_operacional", {}).get("k_final", len(setores_finais))
        finalizar_run(run_id, k_final=k_final_exec, status="done")
        logger.success(f"üèÅ Clusteriza√ß√£o conclu√≠da | run_id={run_id} | K={k_final_exec}")

        return {
            "tenant_id": tenant_id,
            "clusterization_id": clusterization_id,
            "run_id": run_id,
            "algo": algo,
            "k_final": k_final_exec,
            "n_pdvs": len(pdvs),
            "diagnostico": diag,
            "outliers": total_outliers,
            "setores": [
                {
                    "cluster_label": s.cluster_label,
                    "centro_lat": s.centro_lat,
                    "centro_lon": s.centro_lon,
                    "n_pdvs": s.n_pdvs,
                    "raio_med_km": s.raio_med_km,
                    "raio_p95_km": s.raio_p95_km,
                }
                for s in setores_finais
            ],
        }

    except Exception as e:
        logger.error(f"‚ùå Erro durante clusteriza√ß√£o (run_id={run_id}): {e}")
        finalizar_run(run_id, k_final=0, status="error", error=str(e))
        raise
