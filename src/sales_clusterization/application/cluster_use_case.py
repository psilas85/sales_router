# ============================================================
# üì¶ src/sales_clusterization/application/cluster_use_case.py
# ============================================================

from typing import Optional, Dict, Any, List
from loguru import logger
import numpy as np
from src.sales_clusterization.infrastructure.persistence.database_reader import carregar_pdvs
from src.sales_clusterization.infrastructure.persistence.database_writer import (
    criar_run,
    finalizar_run,
    salvar_setores,
    salvar_mapeamento_pdvs,
    salvar_outliers,
)
from src.sales_clusterization.infrastructure.logging.run_logger import snapshot_params
from src.sales_clusterization.domain.k_estimator import estimar_k_inicial, _haversine_km
from src.sales_clusterization.domain.sector_generator import kmeans_setores
from src.sales_clusterization.domain.sector_generator_hybrid import dbscan_kmeans_balanceado
from src.sales_clusterization.domain.validators import checar_raio
from src.sales_clusterization.domain.entities import PDV


# ============================================================
# üß† Detec√ß√£o de Outliers Geogr√°ficos Adaptativa e Suavizada
# ============================================================

from typing import List, Optional
import numpy as np
from sklearn.neighbors import NearestNeighbors
from loguru import logger
from math import radians, sin, cos, sqrt, atan2


# ---------------------------------------
# Dist√¢ncia haversine (km)
# ---------------------------------------
def _haversine_km(a, b):
    R = 6371.0
    lat1, lon1, lat2, lon2 = map(radians, [a[0], a[1], b[0], b[1]])
    dlat, dlon = lat2 - lat1, lon2 - lon1
    h = sin(dlat / 2)**2 + cos(lat1) * cos(lat2) * sin(dlon / 2)**2
    return 2 * R * atan2(sqrt(h), sqrt(1 - h))


# ---------------------------------------
# Fun√ß√£o principal
# ---------------------------------------
def detectar_outliers_geograficos(
    pdvs: List,
    z_thresh: float = 2.0,
    metodo: Optional[str] = None,
    limite_urbano_km: Optional[float] = None,
):
    """
    Detecta outliers geogr√°ficos com base na dist√¢ncia ao vizinho mais pr√≥ximo.

    üîπ Adaptativo ‚Äî sem limite fixo:
       O raio urbano √© estimado automaticamente a partir da densidade local
       (dist√¢ncia m√©dia at√© o 5¬∫ vizinho mais pr√≥ximo).

    üîπ Suavizado:
       O limiar final combina estat√≠sticas globais (Z-score/IQR) e densidade urbana,
       reduzindo falsos positivos em regi√µes densas.
    """
    if len(pdvs) < 5:
        logger.warning("‚ö†Ô∏è Poucos PDVs para detec√ß√£o de outliers ‚Äî nenhum removido.")
        return [(p, False) for p in pdvs]

    coords = np.array([[p.lat, p.lon] for p in pdvs])

    # =====================================================
    # üß≠ 1Ô∏è‚É£ Densidade local ‚Üí limite urbano din√¢mico
    # =====================================================
    k = min(5, len(coords) - 1)
    nn = NearestNeighbors(n_neighbors=k)
    nn.fit(coords)
    dist_k, _ = nn.kneighbors(coords)
    media_k5 = np.mean(dist_k[:, -1]) * 111  # converte graus ‚Üí km

    # limite din√¢mico adaptado ao contexto
    limite_dinamico = np.clip(media_k5 * 7, 4, 12)
    if limite_urbano_km is None:
        limite_urbano_km = limite_dinamico

    # =====================================================
    # üìè 2Ô∏è‚É£ C√°lculo da dist√¢ncia m√≠nima entre vizinhos
    # =====================================================
    dists = []
    for i, a in enumerate(coords):
        vizinhos = [_haversine_km(a, b) for j, b in enumerate(coords) if i != j]
        dists.append(min(vizinhos) if vizinhos else 0.0)

    dist_mean = np.mean(dists)
    dist_std = np.std(dists)
    q1, q3 = np.percentile(dists, [25, 75])
    iqr = q3 - q1

    # =====================================================
    # ‚öôÔ∏è 3Ô∏è‚É£ Sele√ß√£o autom√°tica de m√©todo (se n√£o especificado)
    # =====================================================
    if metodo is None:
        if dist_std < 2:
            metodo = "iqr"
        elif dist_std > 5:
            metodo = "zscore"
        else:
            metodo = "hibrido"

    # =====================================================
    # üìä 4Ô∏è‚É£ Defini√ß√£o de limiar de outlier (com suaviza√ß√£o)
    # =====================================================
    if metodo == "iqr":
        limiar = q3 + 2.5 * iqr
        metodo_desc = f"IQR adaptativo (Q3 + 2.5*IQR = {limiar:.2f} km)"
    elif metodo == "zscore":
        limiar = dist_mean + z_thresh * dist_std
        metodo_desc = f"Z-score adaptativo (Œº + {z_thresh}œÉ = {limiar:.2f} km)"
    else:
        limiar_z = dist_mean + z_thresh * dist_std
        limiar_iqr = q3 + 2.5 * iqr

        # suaviza√ß√£o entre estat√≠stica e limite urbano
        limiar = (min(limiar_z, limiar_iqr) * 0.7) + (limite_urbano_km * 0.3)

        metodo_desc = (
            f"H√≠brido adaptativo suavizado (z={limiar_z:.2f}, iqr={limiar_iqr:.2f}, "
            f"urbano={limite_urbano_km:.2f} ‚Üí final={limiar:.2f} km)"
        )

    # =====================================================
    # üßπ 5Ô∏è‚É£ Detec√ß√£o final
    # =====================================================
    flags = [d > limiar for d in dists]
    removidos = sum(flags)

    logger.info(
        f"üßπ Detec√ß√£o de outliers [{metodo_desc}] | m√©dia={dist_mean:.2f} km | std={dist_std:.2f} | "
        f"densidade m√©dia (k5)={media_k5:.2f} km | limite din√¢mico={limite_dinamico:.2f} km | "
        f"outliers detectados={removidos}/{len(pdvs)}"
    )

    return [(pdvs[i], flags[i]) for i in range(len(pdvs))]



# ============================================================
# üß† Execu√ß√£o principal da clusteriza√ß√£o
# ============================================================
def executar_clusterizacao(
    tenant_id: int,
    uf: Optional[str],
    cidade: Optional[str],
    algo: str,
    k_forcado: Optional[int],
    dias_uteis: int,
    freq: int,
    workday_min: int,
    route_km_max: float,
    service_min: int,
    v_kmh: float,
    alpha_path: float,
    max_pdv_cluster: int,
    descricao: str,
    input_id: str,
    clusterization_id: str,
    excluir_outliers: bool = False,
    z_thresh: float = 3.0,
) -> Dict[str, Any]:
    """
    Executa o fluxo completo de clusteriza√ß√£o com detec√ß√£o robusta de outliers.
    """

    logger.info(
        f"üèÅ Iniciando clusteriza√ß√£o | tenant_id={tenant_id} | {uf}-{cidade} "
        f"| algo={algo} | input_id={input_id} | clusterization_id={clusterization_id}"
    )

    # 1Ô∏è‚É£ Carrega PDVs
    pdvs = carregar_pdvs(tenant_id=tenant_id, input_id=input_id, uf=uf, cidade=cidade)
    if not pdvs:
        raise ValueError(
            f"Nenhum PDV encontrado para tenant_id={tenant_id}, input_id={input_id}, filtros={uf}-{cidade}."
        )
    logger.info(f"‚úÖ {len(pdvs)} PDVs carregados (input_id={input_id}).")

    # 2Ô∏è‚É£ Detecta e salva outliers (modo h√≠brido)
    pdv_flags = detectar_outliers_geograficos(pdvs, z_thresh=z_thresh, metodo="hibrido")
    total_outliers = sum(1 for _, flag in pdv_flags if flag)

    # Salva todos com flag no banco
    try:
        salvar_outliers(tenant_id, clusterization_id, pdv_flags)
        logger.info(f"üóÑÔ∏è {len(pdv_flags)} PDVs registrados com flag de outlier (total={total_outliers}).")
    except Exception as e:
        logger.warning(f"‚ö†Ô∏è Falha ao salvar tabela de outliers: {e}")

    # 3Ô∏è‚É£ Filtra se o usu√°rio optou por excluir
    if excluir_outliers:
        pdvs_filtrados = [p for p, flag in pdv_flags if not flag]
        logger.info(f"üìâ {total_outliers} outliers removidos | {len(pdvs_filtrados)} PDVs restantes.")
        pdvs = pdvs_filtrados
    else:
        logger.info("‚úÖ Outliers inclu√≠dos (nenhum removido).")

    # 4Ô∏è‚É£ Snapshot de par√¢metros
    params = snapshot_params(
        uf=uf,
        cidade=cidade,
        algo=algo,
        k_forcado=k_forcado,
        dias_uteis=dias_uteis,
        freq=freq,
        workday_min=workday_min,
        route_km_max=route_km_max,
        service_min=service_min,
        v_kmh=v_kmh,
        alpha_path=alpha_path,
        n_pdvs=len(pdvs),
        max_pdv_cluster=max_pdv_cluster,
        descricao=descricao,
        input_id=input_id,
        clusterization_id=clusterization_id,
    )

    # 5Ô∏è‚É£ Cria registro de execu√ß√£o
    run_id = criar_run(
        tenant_id=tenant_id,
        uf=uf,
        cidade=cidade,
        algo=algo,
        params=params,
        descricao=descricao,
        input_id=input_id,
        clusterization_id=clusterization_id,
    )
    logger.info(f"üÜï Execu√ß√£o registrada | run_id={run_id} | clusterization_id={clusterization_id}")

    try:
        # 6Ô∏è‚É£ Execu√ß√£o do algoritmo
        if algo == "kmeans":
            if k_forcado:
                k0 = k_forcado
                diag = {"modo": "for√ßado"}
            else:
                k0, diag = estimar_k_inicial(
                    pdvs, workday_min, route_km_max, service_min, v_kmh, dias_uteis, freq, alpha_path
                )

            setores, labels = kmeans_setores(pdvs, k0)
            if not checar_raio(setores, route_km_max):
                k_ref = int(round(k0 * 1.1))
                setores, labels = kmeans_setores(pdvs, k_ref)
                k0 = k_ref
                diag["ajuste_raio"] = k_ref

        elif algo == "dbscan":
            logger.info(f"üîπ Executando DBSCAN h√≠brido balanceado (limite={max_pdv_cluster} PDVs por cluster)...")
            setores, labels = dbscan_kmeans_balanceado(pdvs, max_pdv_cluster=max_pdv_cluster)
            k0 = len(setores)
            diag = {"dbscan_k": k0, "balanceado": True}

        else:
            raise ValueError("Algoritmo n√£o suportado. Use 'kmeans' ou 'dbscan'.")

        # 7Ô∏è‚É£ Persist√™ncia
        mapping = salvar_setores(tenant_id, run_id, setores)
        salvar_mapeamento_pdvs(tenant_id, run_id, mapping, labels, pdvs)
        logger.info(f"‚úÖ Clusteriza√ß√£o salva no banco (run_id={run_id}, clusterization_id={clusterization_id}).")

        # 8Ô∏è‚É£ Finaliza run
        finalizar_run(run_id, k_final=k0, status="done")
        logger.success(f"üèÅ Clusteriza√ß√£o conclu√≠da | run_id={run_id} | K={k0}")

        return {
            "tenant_id": tenant_id,
            "clusterization_id": clusterization_id,
            "run_id": run_id,
            "algo": algo,
            "k_final": k0,
            "n_pdvs": len(pdvs),
            "diagnostico": diag,
            "outliers": total_outliers,
            "setores": [
                {
                    "cluster_label": s.cluster_label,
                    "centro_lat": s.centro_lat,
                    "centro_lon": s.centro_lon,
                    "n_pdvs": s.n_pdvs,
                    "raio_med_km": s.raio_med_km,
                    "raio_p95_km": s.raio_p95_km,
                }
                for s in setores
            ],
        }

    except Exception as e:
        logger.error(f"‚ùå Erro durante clusteriza√ß√£o (run_id={run_id}): {e}")
        finalizar_run(run_id, k_final=0, status="error", error=str(e))
        raise
